## **Hadoop 시스템 환경**

- 다수의 pc를 활용해 빅데이터를 다룬다.

- **분산 저장**

  - 분산 저장의 장점은 클러스터에 컴퓨터를 더하기만 하면 그 컴퓨터의 하드 드라이브가 데이터 저장소의 일부가 된다.
  - Haddop은 클러스터의 모든 하드 드라이브에 걸쳐 분산돼 있는 모든 데이터를  ``단일 파일 시스템``으로 보여준다.
  - ``데이터의 여분도 제공``
  - 클러스터의 컴퓨터 중 하나에 데이터가 없어져도 데이터의 ``백업 복사본``을 클러스터의 다른 컴퓨터에 보관하기에 문제 없다.
  - 이런 상황이 생기면 자동으로 소실된 데이터를 복구하기 때문에 **`` 데이터가 회복력 ``** 이 있어 신뢰 할 수 있다.

- **분산 처리**

  - 데이터를 클러스터 전체에 걸쳐 저장할 뿐만 아니라 그 데이터를 처리할 때도 클러스터의 컴퓨터와 함께한다.

  - Hadoop은 모든 작업을 **``병렬 처리``**!
  (데이터를 다른 양식으로 전환하거나 다른 시스템으로 전송할 때 혹은 집계해야 할 때)

  - 클러스터 내 모든 컴퓨터 CPU에게 이 작업을 분배하여 ``동시에 처리 가능``

  - ``많은 데이터를 신속히 감당 가능``

- #### Hadoop의 장점

  - 빅데이터를 다룰 때 Oracle 데이터베이스에 CPU와 RAID(복수배열 독립 디스크) 추가에 한계
  - 디스크 검색 및 처리 ``속도 우월``
  - ``데이터 손실 위험``이 적다.
  - 클러스터의 가용 자원을 기억해 문제가 생기면 백업 복사본으로 대체 작동
  - 클러스터에 많은 ``CPU를 활용하여 병렬처리``
  - Hadoop 클러스터는 ``수평적 확장``한다. => 더 많은 데이터를 다루거나 더 빨리 처리해야 한다면 클러스터에 컴퓨터를 추가!
  -  수직적 확장 => 머신 수를 늘리는 대신 기존 머신의 성능을 업글해야함! 
  - 대화식 커리 가능
</br>

## **Core Hadoop Ecosystem**

  ##### HDFS``(Hadoop의 데이터 저장 부분)``
  - 가장 근본적인 HDFS = Hadoop 분산 파일 시스템 = 빅데이터를 클러스터의 ``컴퓨터들에 분산 저장하는 시스템``
    (클러스터의 하드 드라이브들을 하나의 거대한 파일 시스템으로 사용)
  - 가장 큰 장점 **``백업 복사본을 사용해 자동으로 손실을 회복``**

  ##### YARN``(Hadoop의 데이터 처리 부분)``
  - 분산 데이터 저장소
  - 컴퓨터 클러스터의 리소스를 관리하는 시스템

  ##### MapReduce
  - ``데이터를 클러스터 전체에 걸쳐 처리하도록 하는 프로그래밍 모델``
  - Map, Reduce 두 개의 구분된 함수이다.
  - 매퍼는 클러스터에 분산돼있는 데이터를 효율적으로 동시에 변형 시킬 수 있음
  - 리듀서는 그 데이터를 집계
    ##### Pig
    - MapReduce 위에 Pig라는 기술이 구축
    - Python 보다 스크립팅 언어(SQL 스타일 구문) 에 더 익숙하다면 Pig가 좋다.
    - Pig는 고수준의 API로써 많은 경우 SQL과 비슷한 스크립트를 작성해 쿼리를 연결하고 복잡한 답을 구할 수 있다.
      (python 작성하지 않아도 된다.)
    => ``pig는 작성된 스크립트를 MapReduce가 읽을 수 있도록 번역하고 MapReudce는 다시 YARN과 HDFS에게 데이터를 처리하고 원하는 답을 가져오게 함``
    - MapReduce 위에 있는 고수준 스크립팅 언어
    ##### Hive
    - Hive는 실제 SQL쿼리를 받고 파일 시스템에 ``분산된 데이터를 SQL 데이터베이스처럼 취급``
    - Hadoop 클러스터에 저장돼 있는 데이터가 내부적으로는 ``관계형 데이터베이스가 아니지만 SQL로 쿼리가능``

  ##### Apache Ambari
  - ``클러스터 전체``를 보여줌
  - 어떤 시스템을 사용하고 ``얼마나 많은 리소스를 사용하는지 시각화``를 통해 보여줌
  - 지금 사용하고 있는 Hortonworks는 Hadoop stack의 제품들 중 하나

  ##### Spark
  - YARN이나 Mesos 어느 기반으로 하던 ``데이터에 쿼리 실행이 가능``
  - MapReudce처럼 python/java/Scala로 스크립트를 작성해야함
  - **클러스터의 데이터를 신속하고 효율적이며 안정적으로 처리하기 위한다면 Spark 활용 할 것!**


  ##### TEZ
  - Spark와 비슷한 기술 사용
  - ``방향성 비사이클 그래프`` 사용
  - MapRduce의 일 할 때 보다 TEZ가 더 유리하다.

  ##### HBASE
    
  - ``클러스터의 데이터를 트랜잭션 플랫폼으로 노출하는 역할``, NoSQL 일종
  **트랜잭션 : 데이터베이스의 상태를 변화(=질의어를 이용하여 DB에 접근하는 것을 의미)시키기 해서 수행하는 작업의 단위**
  - **트랜잭션을 통해 데이터베이스의 안정성을 확보할 수 있다.**
  - ``기둥형 데이터 스토어`` = 단위 시간당 실행되는 트랜잭션의 수가 아주 빠른 데이터베이스
  - 데이터를 웹 애플리케이션이나 웹사이트에 노출시켜 OLTP 트랜잭션을 하는데 적합
    (OLTP(온라인 트랜잭션 처리) - 온라인 뱅킹, 쇼핑, 주문 입력 또는 텍스트 메시지 전송 등 동시에 발생하는 다수의 트랜잭션을 실행하는 데이터 처리 방식)
  => 클러스터에 저장된 데이터를 노출시키고 ``데이터는 Spark나 MapReduce 등에 의해 전환되었을 수도 있고 후에 그 결과를 다른 시스템에 노출시킬 빠른 방법을 제공함``

  ##### Apache STORM
  - ``스트리밍 데이터를 실시간으로 처리``하기 위해 개발
  - ``실시간으로 기계학습을 업데이트``하거나 데이터를 DB에 저장

  ##### OOZIE
  - ``클러스터의 작업을 스케줄링``
  - 일정에 따라 이런 작업을 순차적으로 진행할 수 있도록 스케줄링
  - ex) 데이터를 Hive에 불러와서 Pig를 통해 통합 -> Spark를 통해 쿼리 -> 결과를 HBASE로 변환
      ==> 이 모든 과정을 관리해 안정적이고 일관성 있게 실행

  ##### Zookeeper
  - ``클러스터의 모든 것을 조직화하는 기술``
  - Zookeeper를 사용해 어떤 노드가 살아있는지 추적할 수 있고 여러 애플리케이션이 사용하는 클러스터의 공유 상태를 안정적으로 확인

</br>

###@ 어떻게 외부 데이터를 클러스터와 HDFS로 가져올 수 있나? @

##### Sqoop
  - ``Hadoop의 데이터베이스를 관계형 데이터베이스로 엮어냄``
  - Sqoop은 ``레거시 데이터베이스와 Hadoop을 잇는 연결장치 역할``을 함
    (ODBC나 JDBC로 소통 가능한 데이터는 Sqoop을 통해 HDFS의 파일로 변형 할 수 있음) 
    ``JDBC`` : Java가 데이터베이스를 사용할 수 있도록 연결해주는 응용프로그램 인터페이스인 Java API
    ``ODBC`` : 데이터베이스에 접근하기 위한 소프트웨어의 표준 규격으로, ODBC 문장을 사용하면 여러 종류의 데이터베이스에 접근 할수 있음

##### FLUME
  - ``대규모 웹로그를 안정적으로 클러스터에 불러옴``
  - ex) ``FLUME``은 실시간으로 웹 서버의 웹로그를 감시하고 클러스터에 게시해 ``STORM/Spark Streaming``을 사용해 처리(``kafka``도 데이터 수집하며 좀 더 포괄적으로 사용) => PC 혹은 웹 서버 클러스터에서 모든 종류의 데이터를 수집해 Hadoop 클러스터로 내보냄

</br>

## **External Data Storage**
  - 데이터는 다른 곳에 저장되거나 노출될 수도 있다.
  - MySQL , 어떤 SQL 데이터베이스라도 ``우리 클러스터와 통합 사용 가능``
  - Sqoop을 사용해 ``우리 클러스터로 데이터를 가져올 뿐 아니라 MySQL로 내보내기 가능``
  - Spark와 같은 여러 기술은 JDBC나 ODBC 데이터베이스에 기록 가능
  - 중앙 데이터베이스에 직접 저장하거나 필요하다면 그곳에서 결과를 검색 가능


  ##### Cassandra/MongoDB
  - ``기둥형 데이터 스토어`` = 단위 시간당 실행되는 트랜잭션의 수가 아주 빠른 데이터베이스
  - 웹 애플리케이션 등 ``데이터를 실시간으로 노출하는데 활용 가능``
  - ``실시간 애플리케이션과 클러스터 사이에 Cassandra나 MongoDB 같은 층을 만들어 두는 것을 추천!``
  
    MySQL/Cassandra/MongoDB : 모두 우리 클러스터와 통합 가능한 외부 데이터베이스

</br>

## **Query Engines**

  ##### Apache DRILL
  - ``다양한 NoSQL 데이터베이스에 SQL쿼리를 작성해 사용``할 수 있도록 함
  
  ##### HUE
  - ``Hive, HBase에 잘 작동하는 쿼리를 대화형으로 생성 가능``
  - Cloudera(회사)에서 ``HUE 는 Ambari의 역할``
  - 모든 것을 시각화하고 전체 Hadoop 클러스터에 쿼리를 실행함

  ##### Apache PHOENIX
  - ``Apache DRILL`` 비슷
  - 전체 데이터 스토리지 기술에 걸쳐 SQL 스타일의 쿼리 가능.
  - ACID 특성 보장 OLTP를 제공
  ``ACID`` :  데이터베이스 트랜잭션이 안전하게 수행된다는 것을 보장하기 위한 성질
    - 주식거래,금융업에서 활용되며 관계형 DB 이용
    - 데이터베이스에서 데이터를 처리할 떄 발생할 수 있는 예외적인 상황 줄이고, ``데이터베이스의 무결성을 보호 가능``

  ##### Presto
  - 전체 클러스터에 쿼리를 실행 할 수 있는 또 다른 방법

  ##### Zeppelin
  - 클러스터와의 상호작용과 사용자 인터페이스를 노트북 유형으로 접근


